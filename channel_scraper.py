# -*- coding: utf-8 -*-
"""channel_scraper.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NtiPAIbztRKYTHDtWr3JcHEZkJfCEBZt
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# %cd /content
# !rm -rf vape-classification/
# !git clone https://github.com/dgauraang/vape-classification/
# !mkdir vape-classification/channels_data
# %cd vape-classification
#

import pandas as pd
from bs4 import BeautifulSoup
import requests

readable_data = pd.read_csv('/content/vape-classification/video_classification_data/model-1-data.csv')

channel_url = list(readable_data['Channel_URL'])
print(channel_url[:10])

channel_ids = []
for url in channel_url:
    channel_ids.append(url[32:])
print(channel_ids)

base_url= "https://www.youtube.com/feeds/videos.xml?channel_id="

for id in channel_ids:
    df = pd.DataFrame(columns=['video_title', 'video_url', 'channel_name', 'video_description'])
    url = base_url + id
    html = requests.get(url)
    soup = BeautifulSoup(html.text, "lxml")

    for entry in soup.find_all("entry"):
        video = []
        for title in entry.find_all("title"):
            video.append(title.text)
        for link in entry.find_all("link"):
            video.append(link["href"])
        for name in entry.find_all("name"):
            video.append(name.text)
        for description in entry.find_all("media:description"):
            video.append(description.text)
        df.loc[len(df)] = video

    df.to_excel('channels_data/' + id + ".xlsx")

!zip -r /content/vape-classification/channels_data.zip /content/vape-classification/channels_data